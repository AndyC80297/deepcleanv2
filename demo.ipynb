{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, make sure you set up a directory to store our local container images that you assign to the environment variable `DEEPCLEAN_IMAGES`, then build the training container image:\n",
    "\n",
    "```console\n",
    "apptainer build $DEEPCLEAN_IMAGES/train.sif projects/train/apptainer.def\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepclean.tasks import train\n",
    "from deepclean.base import DeepCleanSandbox, DeepCleanTask\n",
    "from inspect import getsource\n",
    "\n",
    "\n",
    "def print_command(cls, sandbox_type=\"singularity\"):\n",
    "    task_name = cls.__module__ + \".\" + cls.__qualname__\n",
    "    source = getsource(cls)\n",
    "    print(f\"Executing task {task_name}, defined as:\\n{source}\")\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    DEEPCLEAN_IMAGES=~/images/deepclean SANDBOX_TYPE={sandbox_type} law run {task_name} \\\n",
    "        --data-fname ~/deepclean/data/deepclean-1251335314-4097.h5 \\\n",
    "        --output-dir ~/deepcelean/results/law-test \\\n",
    "        --gpus 7 \\\n",
    "        --local-scheduler\n",
    "    \"\"\"\n",
    "    print(cmd)\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by trying to run the \"optimal\" training task using our custom DeepClean sandbox, defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class DeepCleanSandbox(singularity.SingularitySandbox):\n",
      "    sandbox_type = \"deepclean\"\n",
      "\n",
      "    def _get_volumes(self):\n",
      "        volumes = super()._get_volumes()\n",
      "        if self.task and getattr(self.task, \"dev\", False):\n",
      "            volumes[root] = \"/opt/deepclean\"\n",
      "        return volumes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getsource(DeepCleanSandbox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this sandbox does is attempt to map in the current version of the code if a `DeepCleanTask` is run with the `dev=True` option. This task is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class DeepCleanTask(law.SandboxTask):\n",
      "    dev = luigi.BoolParameter(default=False)\n",
      "    gpus = luigi.Parameter(default=\"\")\n",
      "\n",
      "    @property\n",
      "    def singularity_forward_law(self) -> bool:\n",
      "        return False\n",
      "\n",
      "    @property\n",
      "    def singularity_allow_binds(self) -> bool:\n",
      "        return True\n",
      "\n",
      "    @property\n",
      "    def singularity_args(self) -> Callable:\n",
      "        def arg_getter():\n",
      "            if self.gpus:\n",
      "                return [\"--nv\"]\n",
      "            return []\n",
      "        return arg_getter\n",
      "\n",
      "    def sandbox_env(self, env):\n",
      "        if self.gpus:\n",
      "            return {\"CUDA_VISIBLE_DEVICES\": self.gpus}\n",
      "        return {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getsource(DeepCleanTask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, `dev` could also be a sandbox config option, which might be cleaner, but this is moot for now because when we try to run with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing task deepclean.tasks.train.Train, defined as:\n",
      "class Train(DeepCleanTask):\n",
      "    data_fname = luigi.Parameter()\n",
      "    output_dir = luigi.Parameter()\n",
      "    sandbox = f\"{sandbox_type}::{image_root}/train.sif\"\n",
      "\n",
      "    def get_args(self):\n",
      "        return [\n",
      "            \"--config\",\n",
      "            \"/opt/deepclean/projects/train/config.yaml\",\n",
      "            \"--data.fname\",\n",
      "            self.data_fname,\n",
      "            \"--trainer.logger.save_dir\",\n",
      "            self.output_dir,\n",
      "            \"--trainer.max_epochs\",\n",
      "            \"1\"\n",
      "        ]\n",
      "\n",
      "    def run(self):\n",
      "        from train.cli import main\n",
      "\n",
      "        main(self.get_args())\n",
      "\n",
      "    def output(self):\n",
      "        return law.LocalDirectoryTarget(self.output_dir)\n",
      "\n",
      "\n",
      "    DEEPCLEAN_IMAGES=~/images/deepclean SANDBOX_TYPE=deepclean law run deepclean.tasks.train.Train         --data-fname ~/deepclean/data/deepclean-1251335314-4097.h5         --output-dir ~/deepcelean/results/law-test         --gpus 7         --local-scheduler\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "cmd = print_command(train.Train, \"deepclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   Train__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 1826162] Worker Worker(salt=4099067170, workers=1, host=dgx1, username=alec.gunny, pid=1826162) running   \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "ERROR: [pid 1826162] Worker Worker(salt=4099067170, workers=1, host=dgx1, username=alec.gunny, pid=1826162) failed    \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/sandbox/base.py\", line 344, in run\n",
      "    cmd = self.sandbox_inst.cmd(self.create_proxy_cmd())\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/contrib/singularity/sandbox.py\", line 173, in cmd\n",
      "    env = self._get_env()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/sandbox/base.py\", line 241, in _get_env\n",
      "    for name, value in cfg.items(section):\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/config.py\", line 477, in items\n",
      "    options = self.options(section, prefix=prefix, expand_vars=expand_vars,\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/config.py\", line 452, in options\n",
      "    for option in ConfigParser.options(self, section):\n",
      "  File \"/home/alec.gunny/miniconda3/lib/python3.9/configparser.py\", line 675, in options\n",
      "    raise NoSectionError(section) from None\n",
      "configparser.NoSectionError: No section: 'deepclean_sandbox_env'\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Train__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG: There are 1 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 1 pending tasks unique to this worker\n",
      "DEBUG: There are 1 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=4099067170, workers=1, host=dgx1, username=alec.gunny, pid=1826162) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 failed:\n",
      "    - 1 Train(...)\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So evidently implementing a custom sandbox is slightly nontrivial, since it looks like the law global Config looks for a corresponding entry and raises an error when that entry is not there. Note that we hit this error despite the fact that, following the lead for how `law` [handles this for its `contrib` packages](https://github.com/riga/law/blob/2ca2340eab8630f97ade3899e3ad4ca0befbf0a0/law/config.py#L580-L605), at the bottom of `deepclean.tasks.base` we try to insert the relevant defaults into the law Config like so:\n",
    "\n",
    "```python\n",
    "config_defaults = {\r\n",
    "    \"deepclean_sandbox\": {},\r\n",
    "    \"deepclean_sandbox_env\": {},\r\n",
    "    \"deepclean_sandbox_volumes\": {}\r\n",
    "}\r\n",
    "law.util.merge_dicts(\r\n",
    "    law.Config._default_config,\r\n",
    "    config_defaults,\r\n",
    "    deep=True,\r\n",
    "    inp,\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "So\n",
    "## QUESTION #1: What's the best way to map the local repo into our containers when a `dev=True` flag is specified? Is it with a custom sandbox, and if so how do we get such a sandbox to be supported?\n",
    "\n",
    "\n",
    "But barring this, let's move back to using the vanilla `singularity` sandbox and see if we can run with thatce=True\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing task deepclean.tasks.train.Train, defined as:\n",
      "class Train(DeepCleanTask):\n",
      "    data_fname = luigi.Parameter()\n",
      "    output_dir = luigi.Parameter()\n",
      "    sandbox = f\"{sandbox_type}::{image_root}/train.sif\"\n",
      "\n",
      "    def get_args(self):\n",
      "        return [\n",
      "            \"--config\",\n",
      "            \"/opt/deepclean/projects/train/config.yaml\",\n",
      "            \"--data.fname\",\n",
      "            self.data_fname,\n",
      "            \"--trainer.logger.save_dir\",\n",
      "            self.output_dir,\n",
      "            \"--trainer.max_epochs\",\n",
      "            \"1\"\n",
      "        ]\n",
      "\n",
      "    def run(self):\n",
      "        from train.cli import main\n",
      "\n",
      "        main(self.get_args())\n",
      "\n",
      "    def output(self):\n",
      "        return law.LocalDirectoryTarget(self.output_dir)\n",
      "\n",
      "\n",
      "    DEEPCLEAN_IMAGES=~/images/deepclean SANDBOX_TYPE=singularity law run deepclean.tasks.train.Train         --data-fname ~/deepclean/data/deepclean-1251335314-4097.h5         --output-dir ~/deepcelean/results/law-test         --gpus 7         --local-scheduler\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "cmd = print_command(train.Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   Train__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 1826173] Worker Worker(salt=4909706705, workers=1, host=dgx1, username=alec.gunny, pid=1826173) running   \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "\n",
      "\u001b[0;49;35m=============================== entering sandbox ===============================\u001b[0m\n",
      "\u001b[0;49;35mtask   : \u001b[0m\u001b[1;49;39mTrain__home_alec_gunny_False_7_62f9ee1aac\u001b[0m\n",
      "\u001b[0;49;35msandbox: \u001b[0m\u001b[1;49;39msingularity::/home/alec.gunny/images/deepclean/train.sif\u001b[0m\n",
      "\u001b[0;49;35m================================================================================\u001b[0m\n",
      "\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /usr/bin/nvidia-smi required more than 50 (189) bind mounts\n",
      "/home/alec.gunny/.bashrc: line 30: bind: warning: line editing not enabled\n",
      "/home/alec.gunny/miniconda3/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "DEBUG: Checking if \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   Train__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Pending tasks: 0\n",
      "INFO: [pid 1826387] Worker Worker(salt=4909706705, workers=1, host=dgx1, username=alec.gunny, pid=1826173) running   \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "ERROR: [pid 1826387] Worker Worker(salt=4909706705, workers=1, host=dgx1, username=alec.gunny, pid=1826173) failed    \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/law_forward/py/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/law_forward/py/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/projects/deepclean-demo/deepclean/tasks/train.py\", line 30, in run\n",
      "    from train.cli import main\n",
      "ModuleNotFoundError: No module named 'train'\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Train__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "INFO: This progress looks :( because there were failed tasks\n",
      "\n",
      "\u001b[0;49;36m=============================== leaving sandbox ================================\u001b[0m\n",
      "\u001b[0;49;36mtask   : \u001b[0m\u001b[1;49;39mTrain__home_alec_gunny_False_7_62f9ee1aac\u001b[0m\n",
      "\u001b[0;49;36msandbox: \u001b[0m\u001b[1;49;39msingularity::/home/alec.gunny/images/deepclean/train.sif\u001b[0m\n",
      "\u001b[0;49;36m================================================================================\u001b[0m\n",
      "\n",
      "ERROR: [pid 1826173] Worker Worker(salt=4909706705, workers=1, host=dgx1, username=alec.gunny, pid=1826173) failed    \u001b[0;49;32mTrain\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/sandbox/base.py\", line 350, in run\n",
      "    raise Exception(\n",
      "Exception: sandbox 'singularity::/home/alec.gunny/images/deepclean/train.sif' failed with exit code 40, please see the error inside the sandboxed context above for details\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Train__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG: There are 1 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 1 pending tasks unique to this worker\n",
      "DEBUG: There are 1 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=4909706705, workers=1, host=dgx1, username=alec.gunny, pid=1826173) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 failed:\n",
      "    - 1 Train(...)\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So evidently the `train` library isn't visible to the default python interpreter. Can we fix this with the hacky solution of just inserting our site-packages into the front of `sys.path`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing task deepclean.tasks.train.TrainWithInsert, defined as:\n",
      "class TrainWithInsert(Train):\n",
      "    def run(self):\n",
      "        import sys\n",
      "        sys.path.insert(0, \"/usr/local/lib/python3.10/site-packages\")\n",
      "        super().run()\n",
      "\n",
      "\n",
      "    DEEPCLEAN_IMAGES=~/images/deepclean SANDBOX_TYPE=singularity law run deepclean.tasks.train.TrainWithInsert         --data-fname ~/deepclean/data/deepclean-1251335314-4097.h5         --output-dir ~/deepcelean/results/law-test         --gpus 7         --local-scheduler\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "cmd = print_command(train.TrainWithInsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if \u001b[0;49;32mTrainWithInsert\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   TrainWithInsert__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 1826503] Worker Worker(salt=670383571, workers=1, host=dgx1, username=alec.gunny, pid=1826503) running   \u001b[0;49;32mTrainWithInsert\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "\n",
      "\u001b[0;49;35m=============================== entering sandbox ===============================\u001b[0m\n",
      "\u001b[0;49;35mtask   : \u001b[0m\u001b[1;49;39mTrainWithInsert__home_alec_gunny_False_7_62f9ee1aac\u001b[0m\n",
      "\u001b[0;49;35msandbox: \u001b[0m\u001b[1;49;39msingularity::/home/alec.gunny/images/deepclean/train.sif\u001b[0m\n",
      "\u001b[0;49;35m================================================================================\u001b[0m\n",
      "\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /usr/bin/nvidia-smi required more than 50 (189) bind mounts\n",
      "/home/alec.gunny/.bashrc: line 30: bind: warning: line editing not enabled\n",
      "/home/alec.gunny/miniconda3/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "DEBUG: Checking if \u001b[0;49;32mTrainWithInsert\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   TrainWithInsert__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Pending tasks: 0\n",
      "INFO: [pid 1826725] Worker Worker(salt=670383571, workers=1, host=dgx1, username=alec.gunny, pid=1826503) running   \u001b[0;49;32mTrainWithInsert\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "ERROR: [pid 1826725] Worker Worker(salt=670383571, workers=1, host=dgx1, username=alec.gunny, pid=1826503) failed    \u001b[0;49;32mTrainWithInsert\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/law_forward/py/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/law_forward/py/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/projects/deepclean-demo/deepclean/tasks/train.py\", line 42, in run\n",
      "    super().run()\n",
      "  File \"/home/alec.gunny/projects/deepclean-demo/deepclean/tasks/train.py\", line 30, in run\n",
      "    from train.cli import main\n",
      "ModuleNotFoundError: No module named 'train'\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   TrainWithInsert__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "INFO: This progress looks :( because there were failed tasks\n",
      "\n",
      "\u001b[0;49;36m=============================== leaving sandbox ================================\u001b[0m\n",
      "\u001b[0;49;36mtask   : \u001b[0m\u001b[1;49;39mTrainWithInsert__home_alec_gunny_False_7_62f9ee1aac\u001b[0m\n",
      "\u001b[0;49;36msandbox: \u001b[0m\u001b[1;49;39msingularity::/home/alec.gunny/images/deepclean/train.sif\u001b[0m\n",
      "\u001b[0;49;36m================================================================================\u001b[0m\n",
      "\n",
      "ERROR: [pid 1826503] Worker Worker(salt=670383571, workers=1, host=dgx1, username=alec.gunny, pid=1826503) failed    \u001b[0;49;32mTrainWithInsert\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/sandbox/base.py\", line 350, in run\n",
      "    raise Exception(\n",
      "Exception: sandbox 'singularity::/home/alec.gunny/images/deepclean/train.sif' failed with exit code 40, please see the error inside the sandboxed context above for details\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   TrainWithInsert__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG: There are 1 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 1 pending tasks unique to this worker\n",
      "DEBUG: There are 1 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=670383571, workers=1, host=dgx1, username=alec.gunny, pid=1826503) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 failed:\n",
      "    - 1 TrainWithInsert(...)\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason this doesn't work either. So fine, we'll run the training script as a subprocess called with the full path to our desired interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing task deepclean.tasks.train.TrainWithSubprocess, defined as:\n",
      "class TrainWithSubprocess(Train):\n",
      "    def run(self):\n",
      "        import subprocess, shlex\n",
      "\n",
      "        cmd = [\n",
      "            \"/usr/local/bin/python\",\n",
      "            \"/opt/deepclean/projects/train/train\"\n",
      "        ]\n",
      "        cmd += self.get_args()\n",
      "\n",
      "        try:\n",
      "            proc = subprocess.run(\n",
      "                cmd, capture_output=True, check=True, text=True\n",
      "            )\n",
      "        except subprocess.CalledProcessError as e:\n",
      "            raise RuntimeError(\n",
      "                \"Command '{}' failed with return code {} \"\n",
      "                \"and stderr:\\n{}\".format(\n",
      "                    shlex.join(e.cmd), e.returncode, e.stderr\n",
      "                )\n",
      "            ) from None\n",
      "        print(proc.stdout)\n",
      "\n",
      "\n",
      "    DEEPCLEAN_IMAGES=~/images/deepclean SANDBOX_TYPE=singularity law run deepclean.tasks.train.TrainWithSubprocess         --data-fname ~/deepclean/data/deepclean-1251335314-4097.h5         --output-dir ~/deepcelean/results/law-test         --gpus 7         --local-scheduler\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "cmd = print_command(train.TrainWithSubprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if \u001b[0;49;32mTrainWithSubprocess\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   TrainWithSubprocess__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 1826895] Worker Worker(salt=2989404497, workers=1, host=dgx1, username=alec.gunny, pid=1826895) running   \u001b[0;49;32mTrainWithSubprocess\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "\n",
      "\u001b[0;49;35m=============================== entering sandbox ===============================\u001b[0m\n",
      "\u001b[0;49;35mtask   : \u001b[0m\u001b[1;49;39mTrainWithSubprocess__home_alec_gunny_False_7_62f9ee1aac\u001b[0m\n",
      "\u001b[0;49;35msandbox: \u001b[0m\u001b[1;49;39msingularity::/home/alec.gunny/images/deepclean/train.sif\u001b[0m\n",
      "\u001b[0;49;35m================================================================================\u001b[0m\n",
      "\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /usr/bin/nvidia-smi required more than 50 (189) bind mounts\n",
      "/home/alec.gunny/.bashrc: line 30: bind: warning: line editing not enabled\n",
      "/home/alec.gunny/miniconda3/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "DEBUG: Checking if \u001b[0;49;32mTrainWithSubprocess\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test) is complete\n",
      "INFO: Informed scheduler that task   TrainWithSubprocess__home_alec_gunny_False_7_62f9ee1aac   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Pending tasks: 0\n",
      "INFO: [pid 1827079] Worker Worker(salt=2989404497, workers=1, host=dgx1, username=alec.gunny, pid=1826895) running   \u001b[0;49;32mTrainWithSubprocess\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "ERROR: [pid 1827079] Worker Worker(salt=2989404497, workers=1, host=dgx1, username=alec.gunny, pid=1826895) failed    \u001b[0;49;32mTrainWithSubprocess\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/law_forward/py/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/law_forward/py/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/projects/deepclean-demo/deepclean/tasks/train.py\", line 60, in run\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Command '/usr/local/bin/python /opt/deepclean/projects/train/train --config /opt/deepclean/projects/train/config.yaml --data.fname /home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5 --trainer.logger.save_dir /home/alec.gunny/deepcelean/results/law-test --trainer.max_epochs 1' failed with return code 1 and stderr:\n",
      "Global seed set to 101588\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "/usr/local/lib/python3.10/site-packages/jsonargparse/_typehints.py:1204: JsonargparseWarning: \n",
      "    Not possible to serialize an instance of <class 'torch.nn.modules.activation.ReLU'>. It will be represented\n",
      "    as the string ReLU(). If this was set as a default, consider using lazy_instance.\n",
      "\n",
      "  warning(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/deepclean/projects/train/train/__main__.py\", line 4, in <module>\n",
      "    main()\n",
      "  File \"/opt/deepclean/projects/train/train/cli.py\", line 86, in main\n",
      "    cli.trainer.fit(cli.model, cli.datamodule)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 956, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/pytorch/strategies/single_device.py\", line 75, in setup\n",
      "    self.model_to_device()\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/pytorch/strategies/single_device.py\", line 72, in model_to_device\n",
      "    self.model.to(self.root_device)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/lightning/fabric/utilities/device_dtype_mixin.py\", line 54, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 907, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 601, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 905, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   TrainWithSubprocess__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "INFO: This progress looks :( because there were failed tasks\n",
      "\n",
      "\u001b[0;49;36m=============================== leaving sandbox ================================\u001b[0m\n",
      "\u001b[0;49;36mtask   : \u001b[0m\u001b[1;49;39mTrainWithSubprocess__home_alec_gunny_False_7_62f9ee1aac\u001b[0m\n",
      "\u001b[0;49;36msandbox: \u001b[0m\u001b[1;49;39msingularity::/home/alec.gunny/images/deepclean/train.sif\u001b[0m\n",
      "\u001b[0;49;36m================================================================================\u001b[0m\n",
      "\n",
      "ERROR: [pid 1826895] Worker Worker(salt=2989404497, workers=1, host=dgx1, username=alec.gunny, pid=1826895) failed    \u001b[0;49;32mTrainWithSubprocess\u001b[0m(\u001b[1;49;34mdev\u001b[0m=False, \u001b[1;49;34mgpus\u001b[0m=7, \u001b[1;49;34mdata_fname\u001b[0m=/home/alec.gunny/deepclean/data/deepclean-1251335314-4097.h5, \u001b[1;49;34moutput_dir\u001b[0m=/home/alec.gunny/deepcelean/results/law-test)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/luigi/worker.py\", line 138, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/alec.gunny/miniconda3/envs/deepclean-2eRQY7mu-py3.9/lib/python3.9/site-packages/law/sandbox/base.py\", line 350, in run\n",
      "    raise Exception(\n",
      "Exception: sandbox 'singularity::/home/alec.gunny/images/deepclean/train.sif' failed with exit code 40, please see the error inside the sandboxed context above for details\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   TrainWithSubprocess__home_alec_gunny_False_7_62f9ee1aac   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG: There are 1 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 1 pending tasks unique to this worker\n",
      "DEBUG: There are 1 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=2989404497, workers=1, host=dgx1, username=alec.gunny, pid=1826895) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 failed:\n",
      "    - 1 TrainWithSubprocess(...)\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm running into this error above because I'm currently using GPU 0 on this machine for a different project, and its memory is fully occupied. So evidently our override of `sandbox_env` to only expose GPU 7 didn't work because our training task didn't get scheduled there. But at least we know the library got installed properly and has GPU support!\n",
    "\n",
    "## Question #2: How do we leverage the container's python interpreter inside of `run` without having to resort to subprocesses?\n",
    "## Question #3: What's the best way to set up GPU isolation in this context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
